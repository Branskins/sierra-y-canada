{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c75aba71",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e777a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PNG images to JPG\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def convert_png_to_jpg(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Iterate through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        # Check if the file is a PNG\n",
    "        if filename.lower().endswith('.png'):\n",
    "            # Open the PNG image\n",
    "            png_path = os.path.join(input_folder, filename)\n",
    "            with Image.open(png_path) as img:\n",
    "                # Convert RGB mode to ensure compatibility with JPEG\n",
    "                # Some PNGs might have transparency (RGBA), so we use convert('RGB')\n",
    "                rgb_img = img.convert('RGB')\n",
    "                \n",
    "                # Create the new filename with .jpg extension\n",
    "                jpg_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "                jpg_path = os.path.join(output_folder, jpg_filename)\n",
    "                \n",
    "                # Save the image as JPEG\n",
    "                rgb_img.save(jpg_path, 'JPEG')\n",
    "                # print(f'Converted {filename} to {jpg_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcacfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'data/pokemon_sprites/home'\n",
    "output_folder = 'data/test'\n",
    "convert_png_to_jpg(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Normalization\n",
    "import torch\n",
    "\n",
    "def compute_mean_std(dataset):\n",
    "    # Calculate mean and std across entire training set\n",
    "    means = torch.zeros(3)\n",
    "    stds = torch.zeros(3)\n",
    "    for image, _ in dataset:\n",
    "        for c in range(3):\n",
    "            means[c] += image[c].mean()\n",
    "            stds[c] += image[c].std()\n",
    "    \n",
    "    means /= len(dataset)\n",
    "    stds /= len(dataset)\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caf4ab4-c11c-4649-9140-996122f8b4dc",
   "metadata": {},
   "source": [
    "## Build the Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70dc47e-1bb1-4500-85d0-452afc8b1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d352a1-9bdf-46b0-a365-694214128f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PokemonDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, dtype={'label': np.int64})\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28adef20-1aee-4263-a8f5-7c7202bf666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = v2.Compose([\n",
    "    v2.Resize(size=(256,256)),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize(\n",
    "        mean=[211.6778, 206.4363, 198.7163],\n",
    "        std=[61.6068, 63.7380, 70.0831]\n",
    "    )\n",
    "])\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize(size=(256,256)),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize(\n",
    "        mean=[231.0843, 225.8617, 219.1473],\n",
    "        std=[43.8241, 48.9563, 60.1995]\n",
    "    )\n",
    "])\n",
    "train_data = PokemonDataset('data/train_labels.csv', 'data/train', train_transform)\n",
    "test_data = PokemonDataset('data/test_labels.csv', 'data/test', test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f243e774-912f-4dca-8e2d-3cd6933dba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c754495-7385-4d36-a5de-c959f3f60fe1",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ca30f9-505c-4e2d-ad0c-70f31ce1dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce07a3be-d071-493a-a5fa-23dae30b56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.sequential_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 6144),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(6144, 3072),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3072, 1536),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1536, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 151)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.sequential_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5753709-e3ff-4abd-8bd0-db990ddae399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (sequential_stack): Sequential(\n",
       "    (0): Linear(in_features=196608, out_features=6144, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=6144, out_features=3072, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1536, out_features=768, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=384, out_features=151, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork(196608).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f7c0f-3ab3-4127-a422-b6e287b0ac98",
   "metadata": {},
   "source": [
    "## Optimize the Model Paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e9f94-1cde-454e-a808-9fb5489991fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Resets gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        print(pred)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 15 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b9e7f0a-d0f5-42a4-85a9-48f83b756fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>7f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22252196",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faaf83a8-cfe8-4df3-89df-1da8147d1cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.002137  [    4/  677]\n",
      "loss: 5.006292  [   64/  677]\n",
      "loss: 5.000950  [  124/  677]\n",
      "loss: 4.994209  [  184/  677]\n",
      "loss: 5.023993  [  244/  677]\n",
      "loss: 4.998082  [  304/  677]\n",
      "loss: 5.018184  [  364/  677]\n",
      "loss: 5.024626  [  424/  677]\n",
      "loss: 5.032686  [  484/  677]\n",
      "loss: 5.026966  [  544/  677]\n",
      "loss: 5.019811  [  604/  677]\n",
      "loss: 4.997075  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 0.7%, Avg loss: 5.016901 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.993248  [    4/  677]\n",
      "loss: 5.011334  [   64/  677]\n",
      "loss: 5.008106  [  124/  677]\n",
      "loss: 5.015413  [  184/  677]\n",
      "loss: 5.038708  [  244/  677]\n",
      "loss: 4.990975  [  304/  677]\n",
      "loss: 5.011804  [  364/  677]\n",
      "loss: 4.995588  [  424/  677]\n",
      "loss: 5.014423  [  484/  677]\n",
      "loss: 5.006649  [  544/  677]\n",
      "loss: 4.996296  [  604/  677]\n",
      "loss: 4.985583  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 0.7%, Avg loss: 5.015645 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.995092  [    4/  677]\n",
      "loss: 4.990792  [   64/  677]\n",
      "loss: 5.014659  [  124/  677]\n",
      "loss: 4.990383  [  184/  677]\n",
      "loss: 4.969934  [  244/  677]\n",
      "loss: 5.011641  [  304/  677]\n",
      "loss: 5.008018  [  364/  677]\n",
      "loss: 5.004531  [  424/  677]\n",
      "loss: 4.990555  [  484/  677]\n",
      "loss: 5.003092  [  544/  677]\n",
      "loss: 4.992900  [  604/  677]\n",
      "loss: 4.990030  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 0.7%, Avg loss: 5.014166 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.978374  [    4/  677]\n",
      "loss: 5.014602  [   64/  677]\n",
      "loss: 4.973528  [  124/  677]\n",
      "loss: 5.001871  [  184/  677]\n",
      "loss: 4.994370  [  244/  677]\n",
      "loss: 5.010057  [  304/  677]\n",
      "loss: 5.012391  [  364/  677]\n",
      "loss: 4.978137  [  424/  677]\n",
      "loss: 5.000841  [  484/  677]\n",
      "loss: 5.011212  [  544/  677]\n",
      "loss: 5.006073  [  604/  677]\n",
      "loss: 4.970684  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 0.7%, Avg loss: 5.012991 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 5.007942  [    4/  677]\n",
      "loss: 4.997184  [   64/  677]\n",
      "loss: 4.986334  [  124/  677]\n",
      "loss: 4.991703  [  184/  677]\n",
      "loss: 4.975736  [  244/  677]\n",
      "loss: 4.982058  [  304/  677]\n",
      "loss: 4.970212  [  364/  677]\n",
      "loss: 4.994938  [  424/  677]\n",
      "loss: 4.986505  [  484/  677]\n",
      "loss: 4.986629  [  544/  677]\n",
      "loss: 4.999208  [  604/  677]\n",
      "loss: 5.001176  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 0.7%, Avg loss: 5.011418 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 4.983781  [    4/  677]\n",
      "loss: 4.971135  [   64/  677]\n",
      "loss: 4.989581  [  124/  677]\n",
      "loss: 4.987338  [  184/  677]\n",
      "loss: 4.977974  [  244/  677]\n",
      "loss: 4.987926  [  304/  677]\n",
      "loss: 4.975240  [  364/  677]\n",
      "loss: 4.976046  [  424/  677]\n",
      "loss: 4.970655  [  484/  677]\n",
      "loss: 4.997276  [  544/  677]\n",
      "loss: 4.985178  [  604/  677]\n",
      "loss: 4.934426  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 1.3%, Avg loss: 5.009873 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 4.926056  [    4/  677]\n",
      "loss: 4.997697  [   64/  677]\n",
      "loss: 4.974051  [  124/  677]\n",
      "loss: 4.969262  [  184/  677]\n",
      "loss: 5.003867  [  244/  677]\n",
      "loss: 5.001043  [  304/  677]\n",
      "loss: 5.000689  [  364/  677]\n",
      "loss: 4.979608  [  424/  677]\n",
      "loss: 4.973785  [  484/  677]\n",
      "loss: 4.982145  [  544/  677]\n",
      "loss: 4.971724  [  604/  677]\n",
      "loss: 4.978333  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 5.007937 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 4.993250  [    4/  677]\n",
      "loss: 5.002902  [   64/  677]\n",
      "loss: 4.979640  [  124/  677]\n",
      "loss: 4.980444  [  184/  677]\n",
      "loss: 4.960177  [  244/  677]\n",
      "loss: 4.973148  [  304/  677]\n",
      "loss: 4.969963  [  364/  677]\n",
      "loss: 4.980306  [  424/  677]\n",
      "loss: 4.962565  [  484/  677]\n",
      "loss: 4.927531  [  544/  677]\n",
      "loss: 4.972248  [  604/  677]\n",
      "loss: 4.934586  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 5.005891 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 4.969744  [    4/  677]\n",
      "loss: 4.929133  [   64/  677]\n",
      "loss: 4.968384  [  124/  677]\n",
      "loss: 4.967509  [  184/  677]\n",
      "loss: 4.974525  [  244/  677]\n",
      "loss: 4.978761  [  304/  677]\n",
      "loss: 4.967486  [  364/  677]\n",
      "loss: 4.975260  [  424/  677]\n",
      "loss: 4.956028  [  484/  677]\n",
      "loss: 4.970157  [  544/  677]\n",
      "loss: 4.956092  [  604/  677]\n",
      "loss: 4.976761  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 2.6%, Avg loss: 5.003521 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 4.957186  [    4/  677]\n",
      "loss: 4.924912  [   64/  677]\n",
      "loss: 4.962032  [  124/  677]\n",
      "loss: 4.962021  [  184/  677]\n",
      "loss: 4.927962  [  244/  677]\n",
      "loss: 4.975094  [  304/  677]\n",
      "loss: 4.946959  [  364/  677]\n",
      "loss: 4.948704  [  424/  677]\n",
      "loss: 4.973736  [  484/  677]\n",
      "loss: 4.986959  [  544/  677]\n",
      "loss: 4.961685  [  604/  677]\n",
      "loss: 4.955316  [  664/  677]\n",
      "Test Error: \n",
      " Accuracy: 2.0%, Avg loss: 5.000401 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sierra-y-canada-T8CfZQQY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
